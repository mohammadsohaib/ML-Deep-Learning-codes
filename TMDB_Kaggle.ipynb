{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TMDB_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neuroboy-sohaib/ML-Deep-Learning-codes/blob/master/TMDB_Kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR2f7lQo7ptb",
        "colab_type": "code",
        "outputId": "720f5f0a-ef49-4515-9dd1-01941d2db45c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Install a Drive FUSE wrapper.\n",
        " # https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null \n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 130812 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.3-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.3-0ubuntu3~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ml0Umlw7w6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate auth tokens for Colab\n",
        "\n",
        "from google.colab import auth \n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcPfA7V97zPG",
        "colab_type": "code",
        "outputId": "63701885-2096-4b73-f5e7-eb0f4df9dfd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Generate creds for the Drive FUSE library.\n",
        "\n",
        "from oauth2client.client import GoogleCredentials \n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass \n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass() \n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlJWL9Ms72pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2zDvMtA75A5",
        "colab_type": "code",
        "outputId": "9168544a-2d71-43b5-cbaf-197c2671c913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!pip install -q eli5\n",
        "!pip install -q shap\n",
        "!pip install -q catboost\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 102kB 6.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 225kB 4.9MB/s \n",
            "\u001b[?25h  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 60.6MB 1.3MB/s \n",
            "\u001b[?25h[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN2l2SqE9mCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "# Import dataset \n",
        "dataset = pd.read_csv('train_dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRiqDa8vVdn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "\n",
        "# DRAGONS\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import catboost as cat\n",
        "\n",
        "\n",
        "# plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "%matplotlib inline\n",
        "\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hf6MjIFSFob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rmse(y, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp1J1MSpSOH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('/content/drive/Colab Notebooks/train.csv')\n",
        "test = pd.read_csv('/content/drive/Colab Notebooks/test.csv')\n",
        "train.index = train['id']\n",
        "test.index = test['id']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_yd2qhQSaQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.loc[train['id'] == 16,'revenue'] = 192864         \n",
        "train.loc[train['id'] == 90,'budget'] = 30000000                  \n",
        "train.loc[train['id'] == 118,'budget'] = 60000000       \n",
        "train.loc[train['id'] == 149,'budget'] = 18000000       \n",
        "train.loc[train['id'] == 313,'revenue'] = 12000000       \n",
        "train.loc[train['id'] == 451,'revenue'] = 12000000      \n",
        "train.loc[train['id'] == 464,'budget'] = 20000000       \n",
        "train.loc[train['id'] == 470,'budget'] = 13000000       \n",
        "train.loc[train['id'] == 513,'budget'] = 930000         \n",
        "train.loc[train['id'] == 797,'budget'] = 8000000        \n",
        "train.loc[train['id'] == 819,'budget'] = 90000000       \n",
        "train.loc[train['id'] == 850,'budget'] = 90000000       \n",
        "train.loc[train['id'] == 1007,'budget'] = 2              \n",
        "train.loc[train['id'] == 1112,'budget'] = 7500000       \n",
        "train.loc[train['id'] == 1131,'budget'] = 4300000        \n",
        "train.loc[train['id'] == 1359,'budget'] = 10000000       \n",
        "train.loc[train['id'] == 1542,'budget'] = 1             \n",
        "train.loc[train['id'] == 1570,'budget'] = 15800000       \n",
        "train.loc[train['id'] == 1571,'budget'] = 4000000        \n",
        "train.loc[train['id'] == 1714,'budget'] = 46000000       \n",
        "train.loc[train['id'] == 1721,'budget'] = 17500000       \n",
        "train.loc[train['id'] == 1865,'revenue'] = 25000000      \n",
        "train.loc[train['id'] == 1885,'budget'] = 12             \n",
        "train.loc[train['id'] == 2091,'budget'] = 10             \n",
        "train.loc[train['id'] == 2268,'budget'] = 17500000       \n",
        "train.loc[train['id'] == 2491,'budget'] = 6              \n",
        "train.loc[train['id'] == 2602,'budget'] = 31000000       \n",
        "train.loc[train['id'] == 2612,'budget'] = 15000000       \n",
        "train.loc[train['id'] == 2696,'budget'] = 10000000      \n",
        "train.loc[train['id'] == 2801,'budget'] = 10000000       \n",
        "train.loc[train['id'] == 335,'budget'] = 2 \n",
        "train.loc[train['id'] == 348,'budget'] = 12\n",
        "train.loc[train['id'] == 470,'budget'] = 13000000 \n",
        "train.loc[train['id'] == 513,'budget'] = 1100000\n",
        "train.loc[train['id'] == 640,'budget'] = 6 \n",
        "train.loc[train['id'] == 696,'budget'] = 1\n",
        "train.loc[train['id'] == 797,'budget'] = 8000000 \n",
        "train.loc[train['id'] == 850,'budget'] = 1500000\n",
        "train.loc[train['id'] == 1199,'budget'] = 5 \n",
        "train.loc[train['id'] == 1282,'budget'] = 9 \n",
        "train.loc[train['id'] == 1347,'budget'] = 1\n",
        "train.loc[train['id'] == 1755,'budget'] = 2\n",
        "train.loc[train['id'] == 1801,'budget'] = 5\n",
        "train.loc[train['id'] == 1918,'budget'] = 592 \n",
        "train.loc[train['id'] == 2033,'budget'] = 4\n",
        "train.loc[train['id'] == 2118,'budget'] = 344 \n",
        "train.loc[train['id'] == 2252,'budget'] = 130\n",
        "train.loc[train['id'] == 2256,'budget'] = 1 \n",
        "train.loc[train['id'] == 2696,'budget'] = 10000000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBqX6HwCSzF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.loc[test['id'] == 3033,'budget'] = 250 \n",
        "test.loc[test['id'] == 3051,'budget'] = 50\n",
        "test.loc[test['id'] == 3084,'budget'] = 337\n",
        "test.loc[test['id'] == 3224,'budget'] = 4  \n",
        "test.loc[test['id'] == 3594,'budget'] = 25  \n",
        "test.loc[test['id'] == 3619,'budget'] = 500  \n",
        "test.loc[test['id'] == 3831,'budget'] = 3  \n",
        "test.loc[test['id'] == 3935,'budget'] = 500  \n",
        "test.loc[test['id'] == 4049,'budget'] = 995946 \n",
        "test.loc[test['id'] == 4424,'budget'] = 3  \n",
        "test.loc[test['id'] == 4460,'budget'] = 8  \n",
        "test.loc[test['id'] == 4555,'budget'] = 1200000 \n",
        "test.loc[test['id'] == 4624,'budget'] = 30 \n",
        "test.loc[test['id'] == 4645,'budget'] = 500 \n",
        "test.loc[test['id'] == 4709,'budget'] = 450 \n",
        "test.loc[test['id'] == 4839,'budget'] = 7\n",
        "test.loc[test['id'] == 3125,'budget'] = 25 \n",
        "test.loc[test['id'] == 3142,'budget'] = 1\n",
        "test.loc[test['id'] == 3201,'budget'] = 450\n",
        "test.loc[test['id'] == 3222,'budget'] = 6\n",
        "test.loc[test['id'] == 3545,'budget'] = 38\n",
        "test.loc[test['id'] == 3670,'budget'] = 18\n",
        "test.loc[test['id'] == 3792,'budget'] = 19\n",
        "test.loc[test['id'] == 3881,'budget'] = 7\n",
        "test.loc[test['id'] == 3969,'budget'] = 400\n",
        "test.loc[test['id'] == 4196,'budget'] = 6\n",
        "test.loc[test['id'] == 4221,'budget'] = 11\n",
        "test.loc[test['id'] == 4222,'budget'] = 500\n",
        "test.loc[test['id'] == 4285,'budget'] = 11\n",
        "test.loc[test['id'] == 4319,'budget'] = 1\n",
        "test.loc[test['id'] == 4639,'budget'] = 10\n",
        "test.loc[test['id'] == 4719,'budget'] = 45\n",
        "test.loc[test['id'] == 4822,'budget'] = 22\n",
        "test.loc[test['id'] == 4829,'budget'] = 20\n",
        "test.loc[test['id'] == 4969,'budget'] = 20\n",
        "test.loc[test['id'] == 5021,'budget'] = 40 \n",
        "test.loc[test['id'] == 5035,'budget'] = 1 \n",
        "test.loc[test['id'] == 5063,'budget'] = 14 \n",
        "test.loc[test['id'] == 5119,'budget'] = 2 \n",
        "test.loc[test['id'] == 5214,'budget'] = 30 \n",
        "test.loc[test['id'] == 5221,'budget'] = 50 \n",
        "test.loc[test['id'] == 4903,'budget'] = 15\n",
        "test.loc[test['id'] == 4983,'budget'] = 3\n",
        "test.loc[test['id'] == 5102,'budget'] = 28\n",
        "test.loc[test['id'] == 5217,'budget'] = 75\n",
        "test.loc[test['id'] == 5224,'budget'] = 3 \n",
        "test.loc[test['id'] == 5469,'budget'] = 20 \n",
        "test.loc[test['id'] == 5840,'budget'] = 1 \n",
        "test.loc[test['id'] == 5960,'budget'] = 30\n",
        "test.loc[test['id'] == 6506,'budget'] = 11 \n",
        "test.loc[test['id'] == 6553,'budget'] = 280\n",
        "test.loc[test['id'] == 6561,'budget'] = 7\n",
        "test.loc[test['id'] == 6582,'budget'] = 218\n",
        "test.loc[test['id'] == 6638,'budget'] = 5\n",
        "test.loc[test['id'] == 6749,'budget'] = 8 \n",
        "test.loc[test['id'] == 6759,'budget'] = 50 \n",
        "test.loc[test['id'] == 6856,'budget'] = 10\n",
        "test.loc[test['id'] == 6858,'budget'] =  100\n",
        "test.loc[test['id'] == 6876,'budget'] =  250\n",
        "test.loc[test['id'] == 6972,'budget'] = 1\n",
        "test.loc[test['id'] == 7079,'budget'] = 8000000\n",
        "test.loc[test['id'] == 7150,'budget'] = 118\n",
        "test.loc[test['id'] == 6506,'budget'] = 118\n",
        "test.loc[test['id'] == 7225,'budget'] = 6\n",
        "test.loc[test['id'] == 7231,'budget'] = 85\n",
        "test.loc[test['id'] == 5222,'budget'] = 5\n",
        "test.loc[test['id'] == 5322,'budget'] = 90\n",
        "test.loc[test['id'] == 5350,'budget'] = 70\n",
        "test.loc[test['id'] == 5378,'budget'] = 10\n",
        "test.loc[test['id'] == 5545,'budget'] = 80\n",
        "test.loc[test['id'] == 5810,'budget'] = 8\n",
        "test.loc[test['id'] == 5926,'budget'] = 300\n",
        "test.loc[test['id'] == 5927,'budget'] = 4\n",
        "test.loc[test['id'] == 5986,'budget'] = 1\n",
        "test.loc[test['id'] == 6053,'budget'] = 20\n",
        "test.loc[test['id'] == 6104,'budget'] = 1\n",
        "test.loc[test['id'] == 6130,'budget'] = 30\n",
        "test.loc[test['id'] == 6301,'budget'] = 150\n",
        "test.loc[test['id'] == 6276,'budget'] = 100\n",
        "test.loc[test['id'] == 6473,'budget'] = 100\n",
        "test.loc[test['id'] == 6842,'budget'] = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PF6iTu-3aW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainAdditionalFeatures = pd.read_csv('/content/drive/Colab Notebooks//TrainAdditionalFeatures.csv')[['imdb_id','popularity2','rating']]\n",
        "testAdditionalFeatures = pd.read_csv('/content/drive/Colab Notebooks//TestAdditionalFeatures.csv')[['imdb_id','popularity2','rating']]\n",
        "\n",
        "train = pd.merge(train, trainAdditionalFeatures, how='left', on=['imdb_id'])\n",
        "test = pd.merge(test, testAdditionalFeatures, how='left', on=['imdb_id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA8V89573g0n",
        "colab_type": "code",
        "outputId": "c4968730-a83f-456e-b542-6e138fca1cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "vote = pd.read_csv('/content/drive/Colab Notebooks/trainV3.csv')\n",
        "train = pd.merge(train, vote, how='left', on=['imdb_id'])\n",
        "vote.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1040 entries, 0 to 1039\n",
            "Data columns (total 10 columns):\n",
            "title                1040 non-null object\n",
            "budget               1040 non-null int64\n",
            "imdb_id              1037 non-null object\n",
            "original_language    1040 non-null object\n",
            "original_title       1040 non-null object\n",
            "overview             1025 non-null object\n",
            "release_date         1040 non-null object\n",
            "runtime              1032 non-null float64\n",
            "tagline              585 non-null object\n",
            "revenue              1040 non-null int64\n",
            "dtypes: float64(1), int64(2), object(7)\n",
            "memory usage: 81.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyrVovoj8_h2",
        "colab_type": "code",
        "outputId": "72c84f7c-c09b-44cf-b2a6-6a30ef76c04a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "train.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3000 entries, 0 to 2999\n",
            "Data columns (total 34 columns):\n",
            "id                       3000 non-null int64\n",
            "belongs_to_collection    604 non-null object\n",
            "budget_x                 3000 non-null int64\n",
            "genres                   2993 non-null object\n",
            "homepage                 946 non-null object\n",
            "imdb_id                  3000 non-null object\n",
            "original_language_x      3000 non-null object\n",
            "original_title_x         3000 non-null object\n",
            "overview_x               2992 non-null object\n",
            "popularity               3000 non-null float64\n",
            "poster_path              2999 non-null object\n",
            "production_companies     2844 non-null object\n",
            "production_countries     2945 non-null object\n",
            "release_date_x           3000 non-null object\n",
            "runtime_x                2998 non-null float64\n",
            "spoken_languages         2980 non-null object\n",
            "status                   3000 non-null object\n",
            "tagline_x                2403 non-null object\n",
            "title_x                  3000 non-null object\n",
            "Keywords                 2724 non-null object\n",
            "cast                     2987 non-null object\n",
            "crew                     2984 non-null object\n",
            "revenue_x                3000 non-null int64\n",
            "popularity2              2882 non-null float64\n",
            "rating                   2882 non-null float64\n",
            "title_y                  0 non-null object\n",
            "budget_y                 0 non-null float64\n",
            "original_language_y      0 non-null object\n",
            "original_title_y         0 non-null object\n",
            "overview_y               0 non-null object\n",
            "release_date_y           0 non-null object\n",
            "runtime_y                0 non-null float64\n",
            "tagline_y                0 non-null object\n",
            "revenue_y                0 non-null float64\n",
            "dtypes: float64(7), int64(3), object(24)\n",
            "memory usage: 820.3+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-T1SKA93kEm",
        "colab_type": "code",
        "outputId": "4bc9fa9c-9cce-46de-ea0e-0f76b80f8e3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "release_dates = pd.read_csv('/content/drive/Colab Notebooks/release_dates_per_country.csv')\n",
        "release_dates['id'] = range(1,7399)\n",
        "release_dates.drop(['original_title','title'],axis = 1,inplace = True)\n",
        "release_dates.index = release_dates['id']\n",
        "train = pd.merge(train, release_dates, how='left', on=['id'])\n",
        "test = pd.merge(test, release_dates, how='left', on=['id'])\n",
        "release_dates.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-d0da1c93968d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrelease_dates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original_title'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrelease_dates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelease_dates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelease_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelease_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mrelease_dates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     45\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    527\u001b[0m         (self.left_join_keys,\n\u001b[1;32m    528\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                             right_keys.append(\n\u001b[0;32m--> 833\u001b[0;31m                                 right._get_label_or_level_values(rk))\n\u001b[0m\u001b[1;32m    834\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_label_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1701\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_label_or_level_ambiguity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1702\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_label_or_level_ambiguity\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1653\u001b[0m                             \u001b[0mlabel_article\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_article\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m                             label_type=label_type)\n\u001b[0;32m-> 1655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'id' is both an index level and a column label, which is ambiguous."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuqZsqX2TAH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare(df):\n",
        "    global json_cols\n",
        "    global train_dict\n",
        "    #df['totalVotes'] = df['totalVotes'].fillna(6)\n",
        "\n",
        "    df[['release_month','release_day','release_year']]=df['release_date'].str.split('/',expand=True).replace(np.nan, 0).astype(int)\n",
        "    df['release_year'] = df['release_year']\n",
        "    df.loc[ (df['release_year'] <= 18) & (df['release_year'] < 100), \"release_year\"] += 2000\n",
        "    df.loc[ (df['release_year'] > 18)  & (df['release_year'] < 100), \"release_year\"] += 1900\n",
        "    \n",
        "    rating_na = df.groupby([\"release_year\",\"original_language\"])['rating'].mean().reset_index()\n",
        "    df[df.rating.isna()]['rating'] = df.merge(rating_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n",
        "    \n",
        "    vote_count_na = df.groupby([\"release_year\",\"original_language\"])['vote_count'].mean().reset_index()\n",
        "    df[df.vote_count.isna()]['vote_count'] = df.merge(vote_count_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n",
        "    \n",
        "    #budget_na = df.groupby([\"release_year\",\"original_language\"])['budget'].mean().reset_index()\n",
        "    #df.loc[df.budget == 0]['budget'] = df.merge(budget_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n",
        "\n",
        "    df['budget'] = np.log1p(df['budget'])\n",
        "    \n",
        "    df['genders_0_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n",
        "    df['genders_1_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n",
        "    df['genders_2_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n",
        "\n",
        "    \n",
        "    df['_collection_name'] = df['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n",
        "    le = LabelEncoder()\n",
        "    le.fit(list(df['_collection_name'].fillna('')))\n",
        "    df['_collection_name'] = le.transform(df['_collection_name'].fillna('').astype(str))\n",
        "    df['_num_Keywords'] = df['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n",
        "    df['_num_cast'] = df['cast'].apply(lambda x: len(x) if x != {} else 0)\n",
        "    \n",
        "    releaseDate = pd.to_datetime(df['release_date']) \n",
        "    df['release_dayofweek'] = releaseDate.dt.dayofweek \n",
        "    df['release_quarter'] = releaseDate.dt.quarter     \n",
        "\n",
        "    df['_budget_runtime_ratio'] = df['budget']/df['runtime'] \n",
        "    df['_budget_popularity_ratio'] = df['budget']/df['popularity']\n",
        "    df['_budget_year_ratio'] = df['budget']/(df['release_year']*df['release_year'])\n",
        "    df['_releaseYear_popularity_ratio'] = df['release_year']/df['popularity']\n",
        "    df['_releaseYear_popularity_ratio2'] = df['popularity']/df['release_year']\n",
        "\n",
        "\n",
        "    df['meanruntimeByYear'] = df.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\n",
        "    df['meanPopularityByYear'] = df.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\n",
        "    df['meanBudgetByYear'] = df.groupby(\"release_year\")[\"budget\"].aggregate('mean')\n",
        "    df['_popularity_theatrical_ratio'] = df['theatrical']/df['popularity']\n",
        "    df['_budget_theatrical_ratio'] = df['budget']/df['theatrical']\n",
        "    #df['mean_theatrical_ByYear'] = df.groupby(\"release_year\")[\"theatrical\"].aggregate('mean')\n",
        "    df['_popularity_totalVotes_ratio'] = df['vote_count']/df['popularity']\n",
        "    df['_totalVotes_releaseYear_ratio'] = df['vote_count']/df['release_year']\n",
        "    df['_budget_totalVotes_ratio'] = df['budget']/df['vote_count']\n",
        "    \n",
        "    \n",
        "    df['_rating_popularity_ratio'] = df['rating']/df['popularity']\n",
        "    df['_rating_totalVotes_ratio'] = df['vote_count']/df['rating']\n",
        "    df['_budget_rating_ratio'] = df['budget']/df['rating']\n",
        "    df['_runtime_rating_ratio'] = df['runtime']/df['rating']\n",
        "    \n",
        "    \n",
        "    df['has_homepage'] = 0\n",
        "    df.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 1\n",
        "    \n",
        "    df['isbelongs_to_collectionNA'] = 0\n",
        "    df.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 1\n",
        "    \n",
        "    df['isTaglineNA'] = 0\n",
        "    df.loc[df['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n",
        "\n",
        "    df['isOriginalLanguageEng'] = 0 \n",
        "    df.loc[ df['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n",
        "    \n",
        "    df['isTitleDifferent'] = 1\n",
        "    df.loc[ df['original_title'] == df['title'] ,\"isTitleDifferent\"] = 0 \n",
        "\n",
        "    df['isMovieReleased'] = 1\n",
        "    df.loc[ df['status'] != \"Released\" ,\"isMovieReleased\"] = 0 \n",
        "\n",
        "    # get collection id\n",
        "    df['collection_id'] = df['belongs_to_collection'].apply(lambda x : np.nan if len(x)==0 else x[0]['id'])\n",
        "    \n",
        "    df['original_title_letter_count'] = df['original_title'].str.len() \n",
        "    df['original_title_word_count'] = df['original_title'].str.split().str.len() \n",
        "\n",
        "\n",
        "    df['title_word_count'] = df['title'].str.split().str.len()\n",
        "    df['overview_word_count'] = df['overview'].str.split().str.len()\n",
        "    df['tagline_word_count'] = df['tagline'].str.split().str.len()\n",
        "    \n",
        "    df['production_countries_count'] = df['production_countries'].apply(lambda x : len(x))\n",
        "    df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\n",
        "    df['cast_count'] = df['cast'].apply(lambda x : len(x))\n",
        "    df['crew_count'] = df['crew'].apply(lambda x : len(x))\n",
        "\n",
        "    \n",
        "    for col in ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n",
        "        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_dict[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n",
        "        temp = df[col].str.get_dummies(sep=',')\n",
        "        df = pd.concat([df, temp], axis=1, sort=False)\n",
        "    df.drop(['genres_etc'], axis = 1, inplace = True)\n",
        "    \n",
        "    df = df.drop(['belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n",
        "    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n",
        "    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'collection_id','movie_id'\n",
        "    ],axis=1)\n",
        "    \n",
        "    df.fillna(value=0.0, inplace = True) \n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16hxTt-yUnvv",
        "colab_type": "code",
        "outputId": "b50e5b59-67f7-492e-efeb-abd79cd1d625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        }
      },
      "source": [
        "test['revenue'] = np.nan\n",
        "\n",
        "json_cols = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n",
        "\n",
        "def get_dictionary(s):\n",
        "    try:\n",
        "        d = eval(s)\n",
        "    except:\n",
        "        d = {}\n",
        "    return d\n",
        "\n",
        "for col in tqdm(json_cols + ['belongs_to_collection']) :\n",
        "    train[col] = train[col].apply(lambda x : get_dictionary(x))\n",
        "    test[col] = test[col].apply(lambda x : get_dictionary(x))\n",
        "\n",
        "print(train.shape)\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8/8 [00:07<00:00,  1.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(3000, 23)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>belongs_to_collection</th>\n",
              "      <th>budget</th>\n",
              "      <th>genres</th>\n",
              "      <th>homepage</th>\n",
              "      <th>imdb_id</th>\n",
              "      <th>original_language</th>\n",
              "      <th>original_title</th>\n",
              "      <th>overview</th>\n",
              "      <th>popularity</th>\n",
              "      <th>...</th>\n",
              "      <th>release_date</th>\n",
              "      <th>runtime</th>\n",
              "      <th>spoken_languages</th>\n",
              "      <th>status</th>\n",
              "      <th>tagline</th>\n",
              "      <th>title</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>cast</th>\n",
              "      <th>crew</th>\n",
              "      <th>revenue</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n",
              "      <td>14000000</td>\n",
              "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tt2637294</td>\n",
              "      <td>en</td>\n",
              "      <td>Hot Tub Time Machine 2</td>\n",
              "      <td>When Lou, who has become the \"father of the In...</td>\n",
              "      <td>6.575393</td>\n",
              "      <td>...</td>\n",
              "      <td>2/20/15</td>\n",
              "      <td>93.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>The Laws of Space and Time are About to be Vio...</td>\n",
              "      <td>Hot Tub Time Machine 2</td>\n",
              "      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n",
              "      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n",
              "      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n",
              "      <td>12314651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n",
              "      <td>40000000</td>\n",
              "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tt0368933</td>\n",
              "      <td>en</td>\n",
              "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
              "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
              "      <td>8.248895</td>\n",
              "      <td>...</td>\n",
              "      <td>8/6/04</td>\n",
              "      <td>113.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>It can take a lifetime to find true love; she'...</td>\n",
              "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
              "      <td>[{'id': 2505, 'name': 'coronation'}, {'id': 42...</td>\n",
              "      <td>[{'cast_id': 1, 'character': 'Mia Thermopolis'...</td>\n",
              "      <td>[{'credit_id': '52fe43fe9251416c7502563d', 'de...</td>\n",
              "      <td>95149435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>{}</td>\n",
              "      <td>3300000</td>\n",
              "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
              "      <td>http://sonyclassics.com/whiplash/</td>\n",
              "      <td>tt2582802</td>\n",
              "      <td>en</td>\n",
              "      <td>Whiplash</td>\n",
              "      <td>Under the direction of a ruthless instructor, ...</td>\n",
              "      <td>64.299990</td>\n",
              "      <td>...</td>\n",
              "      <td>10/10/14</td>\n",
              "      <td>105.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>The road to greatness can take you to the edge.</td>\n",
              "      <td>Whiplash</td>\n",
              "      <td>[{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...</td>\n",
              "      <td>[{'cast_id': 5, 'character': 'Andrew Neimann',...</td>\n",
              "      <td>[{'credit_id': '54d5356ec3a3683ba0000039', 'de...</td>\n",
              "      <td>13092000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>{}</td>\n",
              "      <td>1200000</td>\n",
              "      <td>[{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...</td>\n",
              "      <td>http://kahaanithefilm.com/</td>\n",
              "      <td>tt1821480</td>\n",
              "      <td>hi</td>\n",
              "      <td>Kahaani</td>\n",
              "      <td>Vidya Bagchi (Vidya Balan) arrives in Kolkata ...</td>\n",
              "      <td>3.174936</td>\n",
              "      <td>...</td>\n",
              "      <td>3/9/12</td>\n",
              "      <td>122.0</td>\n",
              "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
              "      <td>Released</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Kahaani</td>\n",
              "      <td>[{'id': 10092, 'name': 'mystery'}, {'id': 1054...</td>\n",
              "      <td>[{'cast_id': 1, 'character': 'Vidya Bagchi', '...</td>\n",
              "      <td>[{'credit_id': '52fe48779251416c9108d6eb', 'de...</td>\n",
              "      <td>16000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>{}</td>\n",
              "      <td>0</td>\n",
              "      <td>[{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>tt1380152</td>\n",
              "      <td>ko</td>\n",
              "      <td>마린보이</td>\n",
              "      <td>Marine Boy is the story of a former national s...</td>\n",
              "      <td>1.148070</td>\n",
              "      <td>...</td>\n",
              "      <td>2/5/09</td>\n",
              "      <td>118.0</td>\n",
              "      <td>[{'iso_639_1': 'ko', 'name': '한국어/조선말'}]</td>\n",
              "      <td>Released</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Marine Boy</td>\n",
              "      <td>{}</td>\n",
              "      <td>[{'cast_id': 3, 'character': 'Chun-soo', 'cred...</td>\n",
              "      <td>[{'credit_id': '52fe464b9251416c75073b43', 'de...</td>\n",
              "      <td>3923970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                              belongs_to_collection    budget  \\\n",
              "id                                                                    \n",
              "1    1  [{'id': 313576, 'name': 'Hot Tub Time Machine ...  14000000   \n",
              "2    2  [{'id': 107674, 'name': 'The Princess Diaries ...  40000000   \n",
              "3    3                                                 {}   3300000   \n",
              "4    4                                                 {}   1200000   \n",
              "5    5                                                 {}         0   \n",
              "\n",
              "                                               genres  \\\n",
              "id                                                      \n",
              "1                      [{'id': 35, 'name': 'Comedy'}]   \n",
              "2   [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
              "3                       [{'id': 18, 'name': 'Drama'}]   \n",
              "4   [{'id': 53, 'name': 'Thriller'}, {'id': 18, 'n...   \n",
              "5   [{'id': 28, 'name': 'Action'}, {'id': 53, 'nam...   \n",
              "\n",
              "                             homepage    imdb_id original_language  \\\n",
              "id                                                                   \n",
              "1                                 NaN  tt2637294                en   \n",
              "2                                 NaN  tt0368933                en   \n",
              "3   http://sonyclassics.com/whiplash/  tt2582802                en   \n",
              "4          http://kahaanithefilm.com/  tt1821480                hi   \n",
              "5                                 NaN  tt1380152                ko   \n",
              "\n",
              "                              original_title  \\\n",
              "id                                             \n",
              "1                     Hot Tub Time Machine 2   \n",
              "2   The Princess Diaries 2: Royal Engagement   \n",
              "3                                   Whiplash   \n",
              "4                                    Kahaani   \n",
              "5                                       마린보이   \n",
              "\n",
              "                                             overview  popularity  ...  \\\n",
              "id                                                                 ...   \n",
              "1   When Lou, who has become the \"father of the In...    6.575393  ...   \n",
              "2   Mia Thermopolis is now a college graduate and ...    8.248895  ...   \n",
              "3   Under the direction of a ruthless instructor, ...   64.299990  ...   \n",
              "4   Vidya Bagchi (Vidya Balan) arrives in Kolkata ...    3.174936  ...   \n",
              "5   Marine Boy is the story of a former national s...    1.148070  ...   \n",
              "\n",
              "   release_date runtime                                   spoken_languages  \\\n",
              "id                                                                           \n",
              "1       2/20/15    93.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "2        8/6/04   113.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "3      10/10/14   105.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
              "4        3/9/12   122.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
              "5        2/5/09   118.0           [{'iso_639_1': 'ko', 'name': '한국어/조선말'}]   \n",
              "\n",
              "      status                                            tagline  \\\n",
              "id                                                                \n",
              "1   Released  The Laws of Space and Time are About to be Vio...   \n",
              "2   Released  It can take a lifetime to find true love; she'...   \n",
              "3   Released    The road to greatness can take you to the edge.   \n",
              "4   Released                                                NaN   \n",
              "5   Released                                                NaN   \n",
              "\n",
              "                                       title  \\\n",
              "id                                             \n",
              "1                     Hot Tub Time Machine 2   \n",
              "2   The Princess Diaries 2: Royal Engagement   \n",
              "3                                   Whiplash   \n",
              "4                                    Kahaani   \n",
              "5                                 Marine Boy   \n",
              "\n",
              "                                             Keywords  \\\n",
              "id                                                      \n",
              "1   [{'id': 4379, 'name': 'time travel'}, {'id': 9...   \n",
              "2   [{'id': 2505, 'name': 'coronation'}, {'id': 42...   \n",
              "3   [{'id': 1416, 'name': 'jazz'}, {'id': 1523, 'n...   \n",
              "4   [{'id': 10092, 'name': 'mystery'}, {'id': 1054...   \n",
              "5                                                  {}   \n",
              "\n",
              "                                                 cast  \\\n",
              "id                                                      \n",
              "1   [{'cast_id': 4, 'character': 'Lou', 'credit_id...   \n",
              "2   [{'cast_id': 1, 'character': 'Mia Thermopolis'...   \n",
              "3   [{'cast_id': 5, 'character': 'Andrew Neimann',...   \n",
              "4   [{'cast_id': 1, 'character': 'Vidya Bagchi', '...   \n",
              "5   [{'cast_id': 3, 'character': 'Chun-soo', 'cred...   \n",
              "\n",
              "                                                 crew   revenue  \n",
              "id                                                               \n",
              "1   [{'credit_id': '59ac067c92514107af02c8c8', 'de...  12314651  \n",
              "2   [{'credit_id': '52fe43fe9251416c7502563d', 'de...  95149435  \n",
              "3   [{'credit_id': '54d5356ec3a3683ba0000039', 'de...  13092000  \n",
              "4   [{'credit_id': '52fe48779251416c9108d6eb', 'de...  16000000  \n",
              "5   [{'credit_id': '52fe464b9251416c75073b43', 'de...   3923970  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUuH6ECXVmT1",
        "colab_type": "code",
        "outputId": "e623d607-3c97-4e41-9fa9-cf4a5c0a9875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# parse json data and build category dictionary\n",
        "def get_json_dict(df) :\n",
        "    global json_cols\n",
        "    result = dict()\n",
        "    for e_col in json_cols :\n",
        "        d = dict()\n",
        "        rows = df[e_col].values\n",
        "        for row in rows :\n",
        "            if row is None : continue\n",
        "            for i in row :\n",
        "                if i['name'] not in d :\n",
        "                    d[i['name']] = 0\n",
        "                d[i['name']] += 1\n",
        "        result[e_col] = d\n",
        "    return result\n",
        "\n",
        "train_dict = get_json_dict(train)\n",
        "test_dict = get_json_dict(test)\n",
        "\n",
        "\n",
        "# remove cateogry with bias and low frequency\n",
        "for col in json_cols :\n",
        "    \n",
        "    remove = []\n",
        "    train_id = set(list(train_dict[col].keys()))\n",
        "    test_id = set(list(test_dict[col].keys()))   \n",
        "    \n",
        "    remove += list(train_id - test_id) + list(test_id - train_id)\n",
        "    for i in train_id.union(test_id) - set(remove) :\n",
        "        if train_dict[col][i] < 10 or i == '' :\n",
        "            remove += [i]\n",
        "            \n",
        "    for i in remove :\n",
        "        if i in train_dict[col] :\n",
        "            del train_dict[col][i]\n",
        "        if i in test_dict[col] :\n",
        "            del test_dict[col][i]\n",
        "            \n",
        "    print(col, 'size :', len(train_id.union(test_id)), '->', len(train_dict[col]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "genres size : 20 -> 19\n",
            "production_companies size : 7087 -> 77\n",
            "production_countries size : 98 -> 25\n",
            "spoken_languages size : 64 -> 27\n",
            "Keywords size : 11930 -> 358\n",
            "cast size : 75944 -> 376\n",
            "crew size : 68763 -> 516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ7AOkov0JHM",
        "colab_type": "code",
        "outputId": "4309b41f-95bb-47e9-82c6-43608d95eae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "test.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'belongs_to_collection', 'budget', 'genres', 'homepage',\n",
              "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
              "       'popularity', 'poster_path', 'production_companies',\n",
              "       'production_countries', 'release_date', 'runtime', 'spoken_languages',\n",
              "       'status', 'tagline', 'title', 'Keywords', 'cast', 'crew', 'revenue',\n",
              "       'lgbfinal'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-EQugjOWcGW",
        "colab_type": "code",
        "outputId": "abcdfcb5-50ba-49f6-ee93-e68809b24c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# prepare data\n",
        "all_data = prepare(pd.concat([train, test]).reset_index(drop = True))\n",
        "train = all_data.loc[:train.shape[0] - 1,:]\n",
        "test = all_data.loc[train.shape[0]:,:]                           \n",
        "print(train.shape)\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-4db1af3beea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-6531982902d2>\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'release_year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'release_year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"release_year\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1900\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrating_na\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"release_year\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"original_language\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrating_na\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'left'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"release_year\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"original_language\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Column not found: {key}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Column not found: rating'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctXeUwdcg2zU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = list(train.columns)\n",
        "features =  [i for i in features if i != 'id' and i != 'revenue']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meJCPPOEymSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "def score(data, y):\n",
        "    validation_res = pd.DataFrame(\n",
        "    {\"id\": data[\"id\"].values,\n",
        "     \"transactionrevenue\": data[\"revenue\"].values,\n",
        "     \"predictedrevenue\": np.expm1(y)})\n",
        "\n",
        "    validation_res = validation_res.groupby(\"id\")[\"transactionrevenue\", \"predictedrevenue\"].sum().reset_index()\n",
        "    return np.sqrt(mean_squared_error(np.log1p(validation_res[\"transactionrevenue\"].values), \n",
        "                                     np.log1p(validation_res[\"predictedrevenue\"].values)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvYDyqAVypUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "class KFoldValidation():\n",
        "    def __init__(self, data, n_splits=5):\n",
        "        unique_vis = np.array(sorted(data['id'].astype(str).unique()))\n",
        "        folds = GroupKFold(n_splits)\n",
        "        ids = np.arange(data.shape[0])\n",
        "        \n",
        "        self.fold_ids = []\n",
        "        for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n",
        "            self.fold_ids.append([\n",
        "                    ids[data['id'].astype(str).isin(unique_vis[trn_vis])],\n",
        "                    ids[data['id'].astype(str).isin(unique_vis[val_vis])]\n",
        "                ])\n",
        "            \n",
        "    def validate(self, train, test, features, model, name=\"\", prepare_stacking=False, \n",
        "                 fit_params={\"early_stopping_rounds\": 500, \"verbose\": 100, \"eval_metric\": \"rmse\"}):\n",
        "        model.FI = pd.DataFrame(index=features)\n",
        "        full_score = 0\n",
        "        \n",
        "        if prepare_stacking:\n",
        "            test[name] = 0\n",
        "            train[name] = np.NaN\n",
        "        \n",
        "        for fold_id, (trn, val) in enumerate(self.fold_ids):\n",
        "            devel = train[features].iloc[trn]\n",
        "            y_devel = np.log1p(train[\"revenue\"].iloc[trn])\n",
        "            valid = train[features].iloc[val]\n",
        "            y_valid = np.log1p(train[\"revenue\"].iloc[val])\n",
        "                       \n",
        "            print(\"Fold \", fold_id, \":\")\n",
        "            model.fit(devel, y_devel, eval_set=[(valid, y_valid)], **fit_params)\n",
        "            \n",
        "            if len(model.feature_importances_) == len(features):  \n",
        "                model.FI['fold' + str(fold_id)] = model.feature_importances_ / model.feature_importances_.sum()\n",
        "\n",
        "            predictions = model.predict(valid)\n",
        "            predictions[predictions < 0] = 0\n",
        "            print(\"Fold \", fold_id, \" error: \", mean_squared_error(y_valid, predictions)**0.5)\n",
        "            fold_score = score(train.iloc[val], predictions)\n",
        "            full_score += fold_score / len(self.fold_ids)\n",
        "            print(\"Fold \", fold_id, \" score: \", fold_score)\n",
        "            if prepare_stacking:\n",
        "                train[name].iloc[val] = predictions\n",
        "                \n",
        "                test_predictions = model.predict(test[features])\n",
        "                test_predictions[test_predictions < 0] = 0\n",
        "                test[name] += test_predictions / len(self.fold_ids)\n",
        "                \n",
        "        print(\"Final score: \", full_score)\n",
        "        return full_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBE89qO7zW8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Kfolder = KFoldValidation(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6G4oOO3zbI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lgbmodel = lgb.LGBMRegressor(n_estimators=10000, \n",
        "                             objective='regression', \n",
        "                             metric='rmse',\n",
        "                             max_depth = 5,\n",
        "                             num_leaves=30, \n",
        "                             min_child_samples=100,\n",
        "                             learning_rate=0.01,\n",
        "                             boosting = 'gbdt',\n",
        "                             min_data_in_leaf= 10,\n",
        "                             feature_fraction = 0.9,\n",
        "                             bagging_freq = 1,\n",
        "                             bagging_fraction = 0.9,\n",
        "                             importance_type='gain',\n",
        "                             lambda_l1 = 0.2,\n",
        "                             bagging_seed=2019, \n",
        "                             subsample=.8, \n",
        "                             colsample_bytree=.9,\n",
        "                             use_best_model=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e17XwS2zzda2",
        "colab_type": "code",
        "outputId": "94fb16db-f8cf-4948-da0b-85a9c01cd192",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "Kfolder.validate(train, test, features , lgbmodel, name=\"lgbfinal\", prepare_stacking=True) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold  0 :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-0aa622b0de4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mKfolder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlgbmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lgbfinal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepare_stacking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-e345e2057582>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, train, test, features, model, name, prepare_stacking, fit_params)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fold \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_devel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    683\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                                        callbacks=callbacks)\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[0;32m-> 1552\u001b[0;31m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m                 ctypes.byref(self.handle)))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    999\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[1;32m   1002\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m    727\u001b[0m                                                                                              \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m                                                                                              \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                                                                                              self.pandas_categorical)\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_label_from_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_has_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg = (\"DataFrame.dtypes for data must be int, float or bool.\\n\"\n\u001b[1;32m    276\u001b[0m                    \"Did not expect the data types in fields \")\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in fields belongs_to_collection, genres, homepage, imdb_id, original_language, original_title, overview, poster_path, production_companies, production_countries, release_date, spoken_languages, status, tagline, title, Keywords, cast, crew"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9axpMsl-z1RI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}